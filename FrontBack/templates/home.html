<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mood Meter AI: Unveiling Emotions Through AI</title>
    <link rel="stylesheet" href="/static/style.css">
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
</head>

<body>
    <header class="header">
        <h1>Mood Meter AI</h1>
        <p>Experience the New Frontier in Emotion Recognition</p>
    </header>

    <main>
        <section id="welcome" class="section">
            <div class="container">
                <h2>Welcome to Mood Meter AI</h2>
                <p>Hello, welcome to Mood Meter AI, where we employ deep learning neural net models in the recognition of human
                    emotion. Emotion is an extremely nuanced and subjective form of expression, conveyed in many ways and
                    heavily reliant on the idiosyncrasies of human behavior. Our models are trained to identify seven basic emotions: anger, disgust, fear, happiness, sadness,
                    surprise, and neutrality. Beyond these, we leverage Plutchik's wheel to delve into complex emotions,
                    offering a comprehensive analysis of your emotional expression.</p>
                <button class="button" onclick="window.location.href='/record-video'">Start Recording</button>
            </div>
        </section>

        <section id="how-it-works" class="section bg-light">
            <div class="container">
                <h2>How It Works</h2>
                <div class="steps">
                    <div class="step">
                        <h3>1. Record Your Video</h3>
                        <p>Start by recording a video of yourself. Ensure your face is clearly visible and speak
                            naturally.</p>
                    </div>
                    <div class="step">
                        <h3>2. Send It to Our AI</h3>
                        <p>Upload your video. Our backend system will then process it using two specialized
                            convolutional neural networks.</p>
                    </div>
                    <div class="step">
                        <h3>3. Discover Your Emotions</h3>
                        <p>Receive insights about the predominant emotions displayed visually and audibly in your
                            recording.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="example-demo" class="section">
            <div class="container">
                <h2>Example Demo</h2>
                <h3>Consider the video below, where a sample user records themselves acting very angrily.</h3>
                <video controls class="video-size" width="320" height="auto">
                    <source src="../static/home_page/Example_input.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        

            <div class="container">
                <div class="context-columns">
                    <div class="visual-context">
                        <h3>The visual context is interpreted through the following screenshots taken of the user's face:</h3>
                    </div>
                    <div class="audio-context">
                        <h3>The audio context of the model is interpreted through the following wav file:</h3>
                    </div>
                </div>
            </div>

            <div class="container">
                <div class="context-columns">
                    <div class="visual-context">
                        <img src="../static/home_page/screenshots/face_1.jpg" alt="Screenshot 1" class="screenshot">
                        <img src="../static/home_page/screenshots/face_2.jpg" alt="Screenshot 2" class="screenshot">
                        <img src="../static/home_page/screenshots/face_3.jpg" alt="Screenshot 3" class="screenshot">
                    </div>
                    <div class="audio-context">
                        <audio controls>
                            <source src="../static/home_page/audio.wav" type="audio/wav">
                            Your browser does not support the audio element.
                        </audio>
                    </div>
                </div>
            </div>

            <h3>A break down of the emotions detected through both a visual and auditory context are provided by the bar charts
                below.</h3>

            <div class="container">
                <div class="context-columns">
                    <div class="visual-context">
                        {{ plots['Visual_Predictions']|safe }}
                    </div>
                    <div class="audio-context">
                        {{ plots['Audio_Predictions']|safe }}
                    </div>
                </div>
            </div>

            <h3>We then consider complex emotions strictly formed through a combination of expressions in each context.</h3>

            <div class="container">
                <div class="context-columns">
                    <div class="visual-context">
                        {{ plots['Visual_Complex']|safe }}
                    </div>
                    <div class="audio-context">
                        {{ plots['Audio_Complex']|safe }}
                    </div>
                </div>
            </div>

            <h3>Lastly, we combine the auditory and visual contexts of emotional expression to detect the most predominant complex
                emotions.</h3>
            <div class="container">
                <div class="combined-complex">
                    {{ plots['Combined_Complex']|safe }}
                </div>
            </div>

        </section>


        <section id="about-plutchiks-wheel" class="section bg-light">
            <div class="container">
                <h2>About Plutchik's Wheel</h2>
                <div class="flex-container">
                    <img src="../static/home_page/plutchiks_wheel.png" alt="Plutchik's Wheel of Emotions"
                        class="plutchiks-wheel-image">
                    <p style="font-size: 15pt;">Plutchik's Wheel of Emotions is a comprehensive model that illustrates the relationships among the
                        primary emotions and how they combine to form complex emotions. The wheel features eight basic emotions:
                        joy, trust, fear, surprise, sadness, anticipation, anger, and disgust. These primary emotions act as the
                        foundation for more nuanced and complex emotional states by combining in various ways. For example,
                        anticipation and joy together foster optimism, while fear and surprise might combine to create awe.
                        Through understanding Plutchik's Wheel, we gain insight into the intricate web of human emotions and how
                        basic feelings can merge to produce the rich tapestry of human emotional experience.</p>
                </div>
            </div>
        </section>

        <section id="applications" class="section">
            <div class="container">
                <h2>Applications of Emotion Detection</h2>
                <ul class="applications-list">
                    <li>
                        <h3 style="font-size: 15pt;">Mental Health Monitoring and Support</h3>
                        <p style="font-size: 15pt;">Using advanced algorithms, emotion detection technology can monitor subtle changes in behavior and
                            vocal patterns to provide early indicators of mental health issues. This capability can enhance
                            remote therapy sessions, giving therapists insights into a patient's well-being between appointments
                            and enabling prompt and personalized support.</p>
                    </li>
        
                    <li>
                        <h3 style="font-size: 15pt;">Enhanced Customer Service</h3>
                        <p style="font-size: 15pt;"> Emotion detection systems can analyze customer voice inflections and facial expressions during
                            service calls or in virtual chats. This information empowers customer service representatives to
                            adapt their strategies in real time, leading to improved customer experiences, quicker resolution of
                            issues, and higher rates of satisfaction and brand loyalty.</p>
                    </li>
        
                    <li>
                        <h3 style="font-size: 15pt;">Educational Tools and E-Learning</h3>
                        <p style="font-size: 15pt;">Educational software equipped with emotion detection can personalize learning by adapting to the
                            student's mood. If a student appears frustrated, the system might offer hints or adjust the
                            difficulty. Conversely, if the student seems bored, the system could present more challenging
                            material or gamify the learning experience to re-engage them.</p>
                    </li>
                </ul>
            </div>
        </section>



    </main>

    <script src="/static/scripts.js"></script>
</body>

</html>